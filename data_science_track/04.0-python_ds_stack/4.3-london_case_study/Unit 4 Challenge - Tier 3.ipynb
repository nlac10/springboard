{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tia3MP1SJpgj"
   },
   "source": [
    "# Springboard Data Science Career Track Unit 4 Challenge - Tier 3 Complete\n",
    "\n",
    "## Objectives\n",
    "Hey! Great job getting through those challenging DataCamp courses. You're learning a lot in a short span of time. \n",
    "\n",
    "In this notebook, you're going to apply the skills you've been learning, bridging the gap between the controlled environment of DataCamp and the *slightly* messier work that data scientists do with actual datasets!\n",
    "\n",
    "Here’s the mystery we’re going to solve: ***which boroughs of London have seen the greatest increase in housing prices, on average, over the last TWO DECADES?***\n",
    "\n",
    "\n",
    "A borough is just a fancy word for district. You may be familiar with the five boroughs of New York… well, there are 32 boroughs within Greater London [(here's some info for the curious)](https://en.wikipedia.org/wiki/London_boroughs). Some of them are more desirable areas to live in, and the data will reflect that with a greater rise in housing prices.\n",
    "\n",
    "***This is the Tier 3 notebook, which means it's not filled in at all: we'll just give you the skeleton of a project, the brief and the data. It's up to you to play around with it and see what you can find out! Good luck! If you struggle, feel free to look at easier tiers for help; but try to dip in and out of them, as the more independent work you do, the better it is for your learning!***\n",
    "\n",
    "This challenge will make use of only what you learned in the following DataCamp courses: \n",
    "- Prework courses (Introduction to Python for Data Science, Intermediate Python for Data Science)\n",
    "- Data Types for Data Science\n",
    "- Python Data Science Toolbox (Part One) \n",
    "- pandas Foundations\n",
    "- Manipulating DataFrames with pandas\n",
    "- Merging DataFrames with pandas\n",
    "\n",
    "Of the tools, techniques and concepts in the above DataCamp courses, this challenge should require the application of the following: \n",
    "- **pandas**\n",
    "    - **data ingestion and inspection** (pandas Foundations, Module One) \n",
    "    - **exploratory data analysis** (pandas Foundations, Module Two)\n",
    "    - **tidying and cleaning** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **transforming DataFrames** (Manipulating DataFrames with pandas, Module One)\n",
    "    - **subsetting DataFrames with lists** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **filtering DataFrames** (Manipulating DataFrames with pandas, Module One) \n",
    "    - **grouping data** (Manipulating DataFrames with pandas, Module Four) \n",
    "    - **melting data** (Manipulating DataFrames with pandas, Module Three) \n",
    "    - **advanced indexing** (Manipulating DataFrames with pandas, Module Four) \n",
    "- **matplotlib** (Intermediate Python for Data Science, Module One)\n",
    "- **fundamental data types** (Data Types for Data Science, Module One) \n",
    "- **dictionaries** (Intermediate Python for Data Science, Module Two)\n",
    "- **handling dates and times** (Data Types for Data Science, Module Four)\n",
    "- **function definition** (Python Data Science Toolbox - Part One, Module One)\n",
    "- **default arguments, variable length, and scope** (Python Data Science Toolbox - Part One, Module Two) \n",
    "- **lambda functions and error handling** (Python Data Science Toolbox - Part One, Module Four) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ipgd2nV8Jpgl"
   },
   "source": [
    "## The Data Science Pipeline\n",
    "\n",
    "This is Tier Three, so we'll get you started. But after that, it's all in your hands! When you feel done with your investigations, look back over what you've accomplished, and prepare a quick presentation of your findings for the next mentor meeting. \n",
    "\n",
    "Data Science is magical. In this case study, you'll get to apply some complex machine learning algorithms. But as  [David Spiegelhalter](https://www.youtube.com/watch?v=oUs1uvsz0Ok) reminds us, there is no substitute for simply **taking a really, really good look at the data.** Sometimes, this is all we need to answer our question.\n",
    "\n",
    "Data Science projects generally adhere to the four stages of Data Science Pipeline:\n",
    "1. Sourcing and loading \n",
    "2. Cleaning, transforming, and visualizing \n",
    "3. Modeling \n",
    "4. Evaluating and concluding \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zswDqbefJpgm"
   },
   "source": [
    "### 1. Sourcing and Loading \n",
    "\n",
    "Any Data Science project kicks off by importing  ***pandas***. The documentation of this wonderful library can be found [here](https://pandas.pydata.org/). As you've seen, pandas is conveniently connected to the [Numpy](http://www.numpy.org/) and [Matplotlib](https://matplotlib.org/) libraries. \n",
    "\n",
    "***Hint:*** This part of the data science pipeline will test those skills you acquired in the pandas Foundations course, Module One. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aEau5nEvJpgm"
   },
   "source": [
    "#### 1.1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T09:09:44.994418Z",
     "start_time": "2020-08-28T09:09:30.007571Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "7Bt_Q_oPJpgn"
   },
   "outputs": [],
   "source": [
    "# Let's import the pandas, numpy libraries as pd, and np respectively. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koUrawxsJpgq"
   },
   "source": [
    "#### 1.2.  Loading the data\n",
    "Your data comes from the [London Datastore](https://data.london.gov.uk/): a free, open-source data-sharing portal for London-oriented datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Notes:** Prior to looking at the data, I would investigate the source. Is the source reliable? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T09:09:47.855029Z",
     "start_time": "2020-08-28T09:09:44.996066Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "AiLiD4v3Jpgr"
   },
   "outputs": [],
   "source": [
    "# First, make a variable called url_LondonHousePrices, and assign it the following link, enclosed in quotation-marks as a string:\n",
    "# https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\n",
    "\n",
    "url_LondonHousePrices = \"https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\"\n",
    "\n",
    "# The dataset we're interested in contains the Average prices of the houses, \n",
    "# and is actually on a particular sheet of the Excel file. \n",
    "# As a result, we need to specify the sheet name in the read_excel() method.\n",
    "# Put this data into a variable called properties.  \n",
    "properties = pd.read_excel(url_LondonHousePrices, sheet_name='Average price', index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "POukEJXgJpgu"
   },
   "source": [
    "---\n",
    "### 2. Cleaning, transforming, and visualizing\n",
    "This second stage is arguably the most important part of any Data Science project. The first thing to do is take a proper look at the data. z\n",
    "\n",
    "Cleaning forms the majority of this stage, and can be done both before or after Transformation.\n",
    "\n",
    "> **The end goal of data cleaning is to have tidy data. When data is tidy:** \n",
    "    1. Each variable has a column.\n",
    "    2. Each observation forms a row.\n",
    "\n",
    "Keep the end goal in mind as you move through this process, every step will take you closer. \n",
    "\n",
    "\n",
    "\n",
    "***Hint:*** This part of the data science pipeline should test those skills you acquired in: \n",
    "* Intermediate Python for data science, all modules.\n",
    "- pandas Foundations, all modules. \n",
    "- Manipulating DataFrames with pandas, all modules.\n",
    "- Data Types for Data Science, Module Four.\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Workflow\n",
    "\n",
    "> #### 2.1 Explore your Data\n",
    "    * df.describe(), df.info()\n",
    "    * df.columns, df.shape\n",
    "    * df.head(), df.tail()\n",
    "    \n",
    "    Questions:\n",
    "    1. Summarize the data in your own words. What question are you trying to answer?\n",
    "    2. Which features/columns are you interested in?\n",
    "    3. Describe the current df layout. Do the indices make sense?\n",
    "    \n",
    "    Be on the lookout for:\n",
    "    1. nulls\n",
    "    2. duplicates\n",
    "    3. outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Te0Q548tnzZa"
   },
   "source": [
    "**2.1. Exploring your data** \n",
    "\n",
    "Think about your pandas functions for checking out a dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T09:09:47.867594Z",
     "start_time": "2020-08-28T09:09:47.856867Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Rxirxw_qoAJa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 305 entries, 0 to 304\n",
      "Data columns (total 49 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   Unnamed: 0            304 non-null    datetime64[ns]\n",
      " 1   City of London        305 non-null    object        \n",
      " 2   Barking & Dagenham    305 non-null    object        \n",
      " 3   Barnet                305 non-null    object        \n",
      " 4   Bexley                305 non-null    object        \n",
      " 5   Brent                 305 non-null    object        \n",
      " 6   Bromley               305 non-null    object        \n",
      " 7   Camden                305 non-null    object        \n",
      " 8   Croydon               305 non-null    object        \n",
      " 9   Ealing                305 non-null    object        \n",
      " 10  Enfield               305 non-null    object        \n",
      " 11  Greenwich             305 non-null    object        \n",
      " 12  Hackney               305 non-null    object        \n",
      " 13  Hammersmith & Fulham  305 non-null    object        \n",
      " 14  Haringey              305 non-null    object        \n",
      " 15  Harrow                305 non-null    object        \n",
      " 16  Havering              305 non-null    object        \n",
      " 17  Hillingdon            305 non-null    object        \n",
      " 18  Hounslow              305 non-null    object        \n",
      " 19  Islington             305 non-null    object        \n",
      " 20  Kensington & Chelsea  305 non-null    object        \n",
      " 21  Kingston upon Thames  305 non-null    object        \n",
      " 22  Lambeth               305 non-null    object        \n",
      " 23  Lewisham              305 non-null    object        \n",
      " 24  Merton                305 non-null    object        \n",
      " 25  Newham                305 non-null    object        \n",
      " 26  Redbridge             305 non-null    object        \n",
      " 27  Richmond upon Thames  305 non-null    object        \n",
      " 28  Southwark             305 non-null    object        \n",
      " 29  Sutton                305 non-null    object        \n",
      " 30  Tower Hamlets         305 non-null    object        \n",
      " 31  Waltham Forest        305 non-null    object        \n",
      " 32  Wandsworth            305 non-null    object        \n",
      " 33  Westminster           305 non-null    object        \n",
      " 34  Unnamed: 34           0 non-null      float64       \n",
      " 35  Inner London          305 non-null    object        \n",
      " 36  Outer London          305 non-null    object        \n",
      " 37  Unnamed: 37           0 non-null      float64       \n",
      " 38  NORTH EAST            305 non-null    object        \n",
      " 39  NORTH WEST            305 non-null    object        \n",
      " 40  YORKS & THE HUMBER    305 non-null    object        \n",
      " 41  EAST MIDLANDS         305 non-null    object        \n",
      " 42  WEST MIDLANDS         305 non-null    object        \n",
      " 43  EAST OF ENGLAND       305 non-null    object        \n",
      " 44  LONDON                305 non-null    object        \n",
      " 45  SOUTH EAST            305 non-null    object        \n",
      " 46  SOUTH WEST            305 non-null    object        \n",
      " 47  Unnamed: 47           0 non-null      float64       \n",
      " 48  England               305 non-null    object        \n",
      "dtypes: datetime64[ns](1), float64(3), object(45)\n",
      "memory usage: 116.9+ KB\n"
     ]
    }
   ],
   "source": [
    "properties.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T09:17:09.210717Z",
     "start_time": "2020-08-28T09:17:09.199719Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 34</th>\n",
       "      <th>Unnamed: 37</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 34  Unnamed: 37  Unnamed: 47\n",
       "count          0.0          0.0          0.0\n",
       "mean           NaN          NaN          NaN\n",
       "std            NaN          NaN          NaN\n",
       "min            NaN          NaN          NaN\n",
       "25%            NaN          NaN          NaN\n",
       "50%            NaN          NaN          NaN\n",
       "75%            NaN          NaN          NaN\n",
       "max            NaN          NaN          NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the only ones that came back because these are the only \"float type\"\n",
    "# the unnamed: 34, 37, 47 refer to the column number (and how they are blank of NaN so\n",
    "# all in all, these can be dropped)\n",
    "properties.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T09:09:58.471659Z",
     "start_time": "2020-08-28T09:09:58.443748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>City of London</th>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>Croydon</th>\n",
       "      <th>Ealing</th>\n",
       "      <th>Enfield</th>\n",
       "      <th>Greenwich</th>\n",
       "      <th>Hackney</th>\n",
       "      <th>Hammersmith &amp; Fulham</th>\n",
       "      <th>Haringey</th>\n",
       "      <th>Harrow</th>\n",
       "      <th>Havering</th>\n",
       "      <th>Hillingdon</th>\n",
       "      <th>Hounslow</th>\n",
       "      <th>Islington</th>\n",
       "      <th>Kensington &amp; Chelsea</th>\n",
       "      <th>Kingston upon Thames</th>\n",
       "      <th>Lambeth</th>\n",
       "      <th>Lewisham</th>\n",
       "      <th>Merton</th>\n",
       "      <th>Newham</th>\n",
       "      <th>Redbridge</th>\n",
       "      <th>Richmond upon Thames</th>\n",
       "      <th>Southwark</th>\n",
       "      <th>Sutton</th>\n",
       "      <th>Tower Hamlets</th>\n",
       "      <th>Waltham Forest</th>\n",
       "      <th>Wandsworth</th>\n",
       "      <th>Westminster</th>\n",
       "      <th>Unnamed: 34</th>\n",
       "      <th>Inner London</th>\n",
       "      <th>Outer London</th>\n",
       "      <th>Unnamed: 37</th>\n",
       "      <th>NORTH EAST</th>\n",
       "      <th>NORTH WEST</th>\n",
       "      <th>YORKS &amp; THE HUMBER</th>\n",
       "      <th>EAST MIDLANDS</th>\n",
       "      <th>WEST MIDLANDS</th>\n",
       "      <th>EAST OF ENGLAND</th>\n",
       "      <th>LONDON</th>\n",
       "      <th>SOUTH EAST</th>\n",
       "      <th>SOUTH WEST</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>England</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>E09000001</td>\n",
       "      <td>E09000002</td>\n",
       "      <td>E09000003</td>\n",
       "      <td>E09000004</td>\n",
       "      <td>E09000005</td>\n",
       "      <td>E09000006</td>\n",
       "      <td>E09000007</td>\n",
       "      <td>E09000008</td>\n",
       "      <td>E09000009</td>\n",
       "      <td>E09000010</td>\n",
       "      <td>E09000011</td>\n",
       "      <td>E09000012</td>\n",
       "      <td>E09000013</td>\n",
       "      <td>E09000014</td>\n",
       "      <td>E09000015</td>\n",
       "      <td>E09000016</td>\n",
       "      <td>E09000017</td>\n",
       "      <td>E09000018</td>\n",
       "      <td>E09000019</td>\n",
       "      <td>E09000020</td>\n",
       "      <td>E09000021</td>\n",
       "      <td>E09000022</td>\n",
       "      <td>E09000023</td>\n",
       "      <td>E09000024</td>\n",
       "      <td>E09000025</td>\n",
       "      <td>E09000026</td>\n",
       "      <td>E09000027</td>\n",
       "      <td>E09000028</td>\n",
       "      <td>E09000029</td>\n",
       "      <td>E09000030</td>\n",
       "      <td>E09000031</td>\n",
       "      <td>E09000032</td>\n",
       "      <td>E09000033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E13000001</td>\n",
       "      <td>E13000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E12000001</td>\n",
       "      <td>E12000002</td>\n",
       "      <td>E12000003</td>\n",
       "      <td>E12000004</td>\n",
       "      <td>E12000005</td>\n",
       "      <td>E12000006</td>\n",
       "      <td>E12000007</td>\n",
       "      <td>E12000008</td>\n",
       "      <td>E12000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E92000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>91449</td>\n",
       "      <td>50460.2</td>\n",
       "      <td>93284.5</td>\n",
       "      <td>64958.1</td>\n",
       "      <td>71306.6</td>\n",
       "      <td>81671.5</td>\n",
       "      <td>120933</td>\n",
       "      <td>69158.2</td>\n",
       "      <td>79885.9</td>\n",
       "      <td>72514.7</td>\n",
       "      <td>62300.1</td>\n",
       "      <td>61296.5</td>\n",
       "      <td>124903</td>\n",
       "      <td>76287.6</td>\n",
       "      <td>84769.5</td>\n",
       "      <td>68000.1</td>\n",
       "      <td>73834.8</td>\n",
       "      <td>72231.7</td>\n",
       "      <td>92516.5</td>\n",
       "      <td>182695</td>\n",
       "      <td>80875.8</td>\n",
       "      <td>67771</td>\n",
       "      <td>60491.3</td>\n",
       "      <td>82070.6</td>\n",
       "      <td>53539.3</td>\n",
       "      <td>72189.6</td>\n",
       "      <td>109326</td>\n",
       "      <td>67885.2</td>\n",
       "      <td>71537</td>\n",
       "      <td>59865.2</td>\n",
       "      <td>61319.4</td>\n",
       "      <td>88559</td>\n",
       "      <td>133025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78252</td>\n",
       "      <td>72958.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42076.4</td>\n",
       "      <td>43958.5</td>\n",
       "      <td>44803.4</td>\n",
       "      <td>45544.5</td>\n",
       "      <td>48527.5</td>\n",
       "      <td>56701.6</td>\n",
       "      <td>74435.8</td>\n",
       "      <td>64018.9</td>\n",
       "      <td>54705.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53202.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>82202.8</td>\n",
       "      <td>51085.8</td>\n",
       "      <td>93190.2</td>\n",
       "      <td>64787.9</td>\n",
       "      <td>72022.3</td>\n",
       "      <td>81657.6</td>\n",
       "      <td>119509</td>\n",
       "      <td>68951.1</td>\n",
       "      <td>80897.1</td>\n",
       "      <td>73155.2</td>\n",
       "      <td>60993.3</td>\n",
       "      <td>63187.1</td>\n",
       "      <td>122088</td>\n",
       "      <td>78901.2</td>\n",
       "      <td>83396.1</td>\n",
       "      <td>69393.5</td>\n",
       "      <td>75031.1</td>\n",
       "      <td>71051.6</td>\n",
       "      <td>94342.4</td>\n",
       "      <td>182345</td>\n",
       "      <td>81230.1</td>\n",
       "      <td>65381.5</td>\n",
       "      <td>60869.3</td>\n",
       "      <td>79982.7</td>\n",
       "      <td>53153.9</td>\n",
       "      <td>72141.6</td>\n",
       "      <td>111103</td>\n",
       "      <td>64799.1</td>\n",
       "      <td>70893.2</td>\n",
       "      <td>62318.5</td>\n",
       "      <td>60252.1</td>\n",
       "      <td>88641</td>\n",
       "      <td>131468</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75885.7</td>\n",
       "      <td>72937.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42572</td>\n",
       "      <td>43925.4</td>\n",
       "      <td>44528.8</td>\n",
       "      <td>46051.6</td>\n",
       "      <td>49341.3</td>\n",
       "      <td>56593.6</td>\n",
       "      <td>72777.9</td>\n",
       "      <td>63715</td>\n",
       "      <td>54356.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53096.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>79120.7</td>\n",
       "      <td>51269</td>\n",
       "      <td>92247.5</td>\n",
       "      <td>64367.5</td>\n",
       "      <td>72015.8</td>\n",
       "      <td>81449.3</td>\n",
       "      <td>120282</td>\n",
       "      <td>68712.4</td>\n",
       "      <td>81379.9</td>\n",
       "      <td>72190.4</td>\n",
       "      <td>61377.8</td>\n",
       "      <td>63593.3</td>\n",
       "      <td>120636</td>\n",
       "      <td>78521.9</td>\n",
       "      <td>83416.2</td>\n",
       "      <td>69368</td>\n",
       "      <td>74188.7</td>\n",
       "      <td>72098</td>\n",
       "      <td>93465.9</td>\n",
       "      <td>182879</td>\n",
       "      <td>81111.5</td>\n",
       "      <td>66336.5</td>\n",
       "      <td>60288</td>\n",
       "      <td>80661.7</td>\n",
       "      <td>53458.3</td>\n",
       "      <td>72501.4</td>\n",
       "      <td>107325</td>\n",
       "      <td>65763.3</td>\n",
       "      <td>70306.8</td>\n",
       "      <td>63938.7</td>\n",
       "      <td>60871.1</td>\n",
       "      <td>87124.8</td>\n",
       "      <td>132260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76591.6</td>\n",
       "      <td>72714.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42369.7</td>\n",
       "      <td>44434.9</td>\n",
       "      <td>45200.5</td>\n",
       "      <td>45383.8</td>\n",
       "      <td>49442.2</td>\n",
       "      <td>56171.2</td>\n",
       "      <td>73896.8</td>\n",
       "      <td>64113.6</td>\n",
       "      <td>53583.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53201.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>77101.2</td>\n",
       "      <td>53133.5</td>\n",
       "      <td>90762.9</td>\n",
       "      <td>64277.7</td>\n",
       "      <td>72965.6</td>\n",
       "      <td>81124.4</td>\n",
       "      <td>120098</td>\n",
       "      <td>68610</td>\n",
       "      <td>82188.9</td>\n",
       "      <td>71442.9</td>\n",
       "      <td>61927.7</td>\n",
       "      <td>65139.6</td>\n",
       "      <td>121425</td>\n",
       "      <td>79545.6</td>\n",
       "      <td>83567.9</td>\n",
       "      <td>69444.3</td>\n",
       "      <td>73911.4</td>\n",
       "      <td>71890.3</td>\n",
       "      <td>93344.5</td>\n",
       "      <td>184177</td>\n",
       "      <td>81672.8</td>\n",
       "      <td>66388.8</td>\n",
       "      <td>59471</td>\n",
       "      <td>79990.5</td>\n",
       "      <td>54479.8</td>\n",
       "      <td>72228.6</td>\n",
       "      <td>106875</td>\n",
       "      <td>63073.6</td>\n",
       "      <td>69411.9</td>\n",
       "      <td>66233.2</td>\n",
       "      <td>60971.4</td>\n",
       "      <td>87026</td>\n",
       "      <td>133370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76851.6</td>\n",
       "      <td>72591.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42095.8</td>\n",
       "      <td>44267.8</td>\n",
       "      <td>45614.3</td>\n",
       "      <td>46124.2</td>\n",
       "      <td>49455.9</td>\n",
       "      <td>56567.9</td>\n",
       "      <td>74455.3</td>\n",
       "      <td>64623.2</td>\n",
       "      <td>54786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53590.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 City of London Barking & Dagenham     Barnet     Bexley      Brent    Bromley     Camden    Croydon     Ealing    Enfield  Greenwich    Hackney Hammersmith & Fulham   Haringey     Harrow   Havering Hillingdon   Hounslow  Islington Kensington & Chelsea Kingston upon Thames    Lambeth   Lewisham     Merton     Newham  Redbridge Richmond upon Thames  Southwark     Sutton Tower Hamlets Waltham Forest Wandsworth Westminster  Unnamed: 34 Inner London Outer London  Unnamed: 37 NORTH EAST NORTH WEST YORKS & THE HUMBER EAST MIDLANDS WEST MIDLANDS EAST OF ENGLAND     LONDON SOUTH EAST SOUTH WEST  Unnamed: 47    England\n",
       "0        NaT      E09000001          E09000002  E09000003  E09000004  E09000005  E09000006  E09000007  E09000008  E09000009  E09000010  E09000011  E09000012            E09000013  E09000014  E09000015  E09000016  E09000017  E09000018  E09000019            E09000020            E09000021  E09000022  E09000023  E09000024  E09000025  E09000026            E09000027  E09000028  E09000029     E09000030      E09000031  E09000032   E09000033          NaN    E13000001    E13000002          NaN  E12000001  E12000002          E12000003     E12000004     E12000005       E12000006  E12000007  E12000008  E12000009          NaN  E92000001\n",
       "1 1995-01-01          91449            50460.2    93284.5    64958.1    71306.6    81671.5     120933    69158.2    79885.9    72514.7    62300.1    61296.5               124903    76287.6    84769.5    68000.1    73834.8    72231.7    92516.5               182695              80875.8      67771    60491.3    82070.6    53539.3    72189.6               109326    67885.2      71537       59865.2        61319.4      88559      133025          NaN        78252      72958.8          NaN    42076.4    43958.5            44803.4       45544.5       48527.5         56701.6    74435.8    64018.9    54705.2          NaN    53202.8\n",
       "2 1995-02-01        82202.8            51085.8    93190.2    64787.9    72022.3    81657.6     119509    68951.1    80897.1    73155.2    60993.3    63187.1               122088    78901.2    83396.1    69393.5    75031.1    71051.6    94342.4               182345              81230.1    65381.5    60869.3    79982.7    53153.9    72141.6               111103    64799.1    70893.2       62318.5        60252.1      88641      131468          NaN      75885.7      72937.9          NaN      42572    43925.4            44528.8       46051.6       49341.3         56593.6    72777.9      63715    54356.1          NaN    53096.2\n",
       "3 1995-03-01        79120.7              51269    92247.5    64367.5    72015.8    81449.3     120282    68712.4    81379.9    72190.4    61377.8    63593.3               120636    78521.9    83416.2      69368    74188.7      72098    93465.9               182879              81111.5    66336.5      60288    80661.7    53458.3    72501.4               107325    65763.3    70306.8       63938.7        60871.1    87124.8      132260          NaN      76591.6      72714.5          NaN    42369.7    44434.9            45200.5       45383.8       49442.2         56171.2    73896.8    64113.6    53583.1          NaN    53201.3\n",
       "4 1995-04-01        77101.2            53133.5    90762.9    64277.7    72965.6    81124.4     120098      68610    82188.9    71442.9    61927.7    65139.6               121425    79545.6    83567.9    69444.3    73911.4    71890.3    93344.5               184177              81672.8    66388.8      59471    79990.5    54479.8    72228.6               106875    63073.6    69411.9       66233.2        60971.4      87026      133370          NaN      76851.6      72591.9          NaN    42095.8    44267.8            45614.3       46124.2       49455.9         56567.9    74455.3    64623.2      54786          NaN    53590.9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Notes:** We are interested only in the 32 boroughs of London. So after cleaning everything, really you drop those. The format of the excel is multi-layered.\n",
    "\n",
    "- City of London:\n",
    "    * list of 32 boroughs\n",
    "- Inner London\n",
    "    * total mean of list of inner boroughs (12)\n",
    "- Outer London\n",
    "    * boroughs (20) \n",
    "- England \n",
    "    * housing prices overall as whole (use for comparison)\n",
    "    * inner + outer london total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-28T09:34:06.738486Z",
     "start_time": "2020-08-28T09:34:06.706685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>City of London</th>\n",
       "      <th>Barking &amp; Dagenham</th>\n",
       "      <th>Barnet</th>\n",
       "      <th>Bexley</th>\n",
       "      <th>Brent</th>\n",
       "      <th>Bromley</th>\n",
       "      <th>Camden</th>\n",
       "      <th>Croydon</th>\n",
       "      <th>Ealing</th>\n",
       "      <th>Enfield</th>\n",
       "      <th>Greenwich</th>\n",
       "      <th>Hackney</th>\n",
       "      <th>Hammersmith &amp; Fulham</th>\n",
       "      <th>Haringey</th>\n",
       "      <th>Harrow</th>\n",
       "      <th>Havering</th>\n",
       "      <th>Hillingdon</th>\n",
       "      <th>Hounslow</th>\n",
       "      <th>Islington</th>\n",
       "      <th>Kensington &amp; Chelsea</th>\n",
       "      <th>Kingston upon Thames</th>\n",
       "      <th>Lambeth</th>\n",
       "      <th>Lewisham</th>\n",
       "      <th>Merton</th>\n",
       "      <th>Newham</th>\n",
       "      <th>Redbridge</th>\n",
       "      <th>Richmond upon Thames</th>\n",
       "      <th>Southwark</th>\n",
       "      <th>Sutton</th>\n",
       "      <th>Tower Hamlets</th>\n",
       "      <th>Waltham Forest</th>\n",
       "      <th>Wandsworth</th>\n",
       "      <th>Westminster</th>\n",
       "      <th>Unnamed: 34</th>\n",
       "      <th>Inner London</th>\n",
       "      <th>Outer London</th>\n",
       "      <th>Unnamed: 37</th>\n",
       "      <th>NORTH EAST</th>\n",
       "      <th>NORTH WEST</th>\n",
       "      <th>YORKS &amp; THE HUMBER</th>\n",
       "      <th>EAST MIDLANDS</th>\n",
       "      <th>WEST MIDLANDS</th>\n",
       "      <th>EAST OF ENGLAND</th>\n",
       "      <th>LONDON</th>\n",
       "      <th>SOUTH EAST</th>\n",
       "      <th>SOUTH WEST</th>\n",
       "      <th>Unnamed: 47</th>\n",
       "      <th>England</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>756407</td>\n",
       "      <td>297426</td>\n",
       "      <td>514668</td>\n",
       "      <td>338346</td>\n",
       "      <td>473849</td>\n",
       "      <td>434257</td>\n",
       "      <td>890288</td>\n",
       "      <td>365875</td>\n",
       "      <td>475592</td>\n",
       "      <td>388053</td>\n",
       "      <td>397828</td>\n",
       "      <td>555779</td>\n",
       "      <td>725253</td>\n",
       "      <td>550393</td>\n",
       "      <td>446095</td>\n",
       "      <td>367679</td>\n",
       "      <td>398547</td>\n",
       "      <td>397246</td>\n",
       "      <td>629281</td>\n",
       "      <td>1.27544e+06</td>\n",
       "      <td>502895</td>\n",
       "      <td>510045</td>\n",
       "      <td>410983</td>\n",
       "      <td>504702</td>\n",
       "      <td>359106</td>\n",
       "      <td>414968</td>\n",
       "      <td>657619</td>\n",
       "      <td>499663</td>\n",
       "      <td>373534</td>\n",
       "      <td>431290</td>\n",
       "      <td>418743</td>\n",
       "      <td>585174</td>\n",
       "      <td>948507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>569219</td>\n",
       "      <td>421920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129756</td>\n",
       "      <td>166137</td>\n",
       "      <td>165119</td>\n",
       "      <td>193549</td>\n",
       "      <td>197938</td>\n",
       "      <td>291700</td>\n",
       "      <td>478858</td>\n",
       "      <td>322863</td>\n",
       "      <td>258449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>813770</td>\n",
       "      <td>299421</td>\n",
       "      <td>528577</td>\n",
       "      <td>337523</td>\n",
       "      <td>488784</td>\n",
       "      <td>442189</td>\n",
       "      <td>863171</td>\n",
       "      <td>364540</td>\n",
       "      <td>474627</td>\n",
       "      <td>393033</td>\n",
       "      <td>396858</td>\n",
       "      <td>567269</td>\n",
       "      <td>729659</td>\n",
       "      <td>544194</td>\n",
       "      <td>450373</td>\n",
       "      <td>367502</td>\n",
       "      <td>397385</td>\n",
       "      <td>401911</td>\n",
       "      <td>643335</td>\n",
       "      <td>1.24853e+06</td>\n",
       "      <td>508405</td>\n",
       "      <td>519956</td>\n",
       "      <td>416885</td>\n",
       "      <td>517489</td>\n",
       "      <td>361920</td>\n",
       "      <td>421319</td>\n",
       "      <td>657974</td>\n",
       "      <td>496718</td>\n",
       "      <td>368908</td>\n",
       "      <td>441364</td>\n",
       "      <td>427416</td>\n",
       "      <td>592251</td>\n",
       "      <td>905951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>571439</td>\n",
       "      <td>425263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131515</td>\n",
       "      <td>167490</td>\n",
       "      <td>165441</td>\n",
       "      <td>195268</td>\n",
       "      <td>200858</td>\n",
       "      <td>290623</td>\n",
       "      <td>472872</td>\n",
       "      <td>323122</td>\n",
       "      <td>258241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>810455</td>\n",
       "      <td>304778</td>\n",
       "      <td>526670</td>\n",
       "      <td>333340</td>\n",
       "      <td>501533</td>\n",
       "      <td>441058</td>\n",
       "      <td>838170</td>\n",
       "      <td>365226</td>\n",
       "      <td>473162</td>\n",
       "      <td>386806</td>\n",
       "      <td>403730</td>\n",
       "      <td>573270</td>\n",
       "      <td>735538</td>\n",
       "      <td>553640</td>\n",
       "      <td>453155</td>\n",
       "      <td>366447</td>\n",
       "      <td>403945</td>\n",
       "      <td>406930</td>\n",
       "      <td>655061</td>\n",
       "      <td>1.23018e+06</td>\n",
       "      <td>504867</td>\n",
       "      <td>520403</td>\n",
       "      <td>420341</td>\n",
       "      <td>515391</td>\n",
       "      <td>368687</td>\n",
       "      <td>414268</td>\n",
       "      <td>648147</td>\n",
       "      <td>507466</td>\n",
       "      <td>372899</td>\n",
       "      <td>447629</td>\n",
       "      <td>432270</td>\n",
       "      <td>605559</td>\n",
       "      <td>922687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>577554</td>\n",
       "      <td>425804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131952</td>\n",
       "      <td>166796</td>\n",
       "      <td>165407</td>\n",
       "      <td>194808</td>\n",
       "      <td>200969</td>\n",
       "      <td>291944</td>\n",
       "      <td>477779</td>\n",
       "      <td>324357</td>\n",
       "      <td>258751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>826227</td>\n",
       "      <td>304579</td>\n",
       "      <td>525678</td>\n",
       "      <td>332920</td>\n",
       "      <td>494770</td>\n",
       "      <td>439178</td>\n",
       "      <td>804713</td>\n",
       "      <td>364413</td>\n",
       "      <td>477369</td>\n",
       "      <td>392721</td>\n",
       "      <td>401559</td>\n",
       "      <td>566979</td>\n",
       "      <td>719932</td>\n",
       "      <td>554123</td>\n",
       "      <td>453783</td>\n",
       "      <td>367102</td>\n",
       "      <td>403300</td>\n",
       "      <td>413132</td>\n",
       "      <td>645212</td>\n",
       "      <td>1.19044e+06</td>\n",
       "      <td>488211</td>\n",
       "      <td>515947</td>\n",
       "      <td>421258</td>\n",
       "      <td>509006</td>\n",
       "      <td>369972</td>\n",
       "      <td>411874</td>\n",
       "      <td>643769</td>\n",
       "      <td>513615</td>\n",
       "      <td>369917</td>\n",
       "      <td>452040</td>\n",
       "      <td>434921</td>\n",
       "      <td>600642</td>\n",
       "      <td>927735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>574464</td>\n",
       "      <td>424942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129462</td>\n",
       "      <td>166640</td>\n",
       "      <td>166494</td>\n",
       "      <td>194674</td>\n",
       "      <td>200116</td>\n",
       "      <td>291196</td>\n",
       "      <td>474156</td>\n",
       "      <td>323278</td>\n",
       "      <td>258880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>776894</td>\n",
       "      <td>306390</td>\n",
       "      <td>522639</td>\n",
       "      <td>333657</td>\n",
       "      <td>432188</td>\n",
       "      <td>436080</td>\n",
       "      <td>825336</td>\n",
       "      <td>367585</td>\n",
       "      <td>475492</td>\n",
       "      <td>393255</td>\n",
       "      <td>405337</td>\n",
       "      <td>559758</td>\n",
       "      <td>719751</td>\n",
       "      <td>559426</td>\n",
       "      <td>450109</td>\n",
       "      <td>365861</td>\n",
       "      <td>407706</td>\n",
       "      <td>410071</td>\n",
       "      <td>630659</td>\n",
       "      <td>1.19405e+06</td>\n",
       "      <td>490420</td>\n",
       "      <td>519410</td>\n",
       "      <td>415893</td>\n",
       "      <td>501570</td>\n",
       "      <td>363114</td>\n",
       "      <td>413882</td>\n",
       "      <td>650949</td>\n",
       "      <td>510619</td>\n",
       "      <td>374775</td>\n",
       "      <td>450989</td>\n",
       "      <td>435568</td>\n",
       "      <td>601650</td>\n",
       "      <td>955265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>573932</td>\n",
       "      <td>423311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129658</td>\n",
       "      <td>165808</td>\n",
       "      <td>164499</td>\n",
       "      <td>194855</td>\n",
       "      <td>200896</td>\n",
       "      <td>288781</td>\n",
       "      <td>468983</td>\n",
       "      <td>322512</td>\n",
       "      <td>256875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>247951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>737275</td>\n",
       "      <td>301283</td>\n",
       "      <td>519306</td>\n",
       "      <td>336302</td>\n",
       "      <td>427126</td>\n",
       "      <td>438682</td>\n",
       "      <td>807124</td>\n",
       "      <td>369568</td>\n",
       "      <td>469662</td>\n",
       "      <td>400182</td>\n",
       "      <td>398024</td>\n",
       "      <td>552785</td>\n",
       "      <td>728698</td>\n",
       "      <td>565582</td>\n",
       "      <td>446900</td>\n",
       "      <td>365886</td>\n",
       "      <td>404843</td>\n",
       "      <td>409569</td>\n",
       "      <td>648969</td>\n",
       "      <td>1.23176e+06</td>\n",
       "      <td>487696</td>\n",
       "      <td>521705</td>\n",
       "      <td>413462</td>\n",
       "      <td>500651</td>\n",
       "      <td>360934</td>\n",
       "      <td>424631</td>\n",
       "      <td>655378</td>\n",
       "      <td>505499</td>\n",
       "      <td>372581</td>\n",
       "      <td>456436</td>\n",
       "      <td>437333</td>\n",
       "      <td>605560</td>\n",
       "      <td>960943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>575132</td>\n",
       "      <td>423156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129504</td>\n",
       "      <td>164893</td>\n",
       "      <td>165818</td>\n",
       "      <td>194553</td>\n",
       "      <td>198644</td>\n",
       "      <td>290814</td>\n",
       "      <td>478576</td>\n",
       "      <td>321972</td>\n",
       "      <td>256577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>747611</td>\n",
       "      <td>303653</td>\n",
       "      <td>518542</td>\n",
       "      <td>334765</td>\n",
       "      <td>423161</td>\n",
       "      <td>435532</td>\n",
       "      <td>815512</td>\n",
       "      <td>371227</td>\n",
       "      <td>466491</td>\n",
       "      <td>390589</td>\n",
       "      <td>396833</td>\n",
       "      <td>558321</td>\n",
       "      <td>740048</td>\n",
       "      <td>563151</td>\n",
       "      <td>447269</td>\n",
       "      <td>362423</td>\n",
       "      <td>406622</td>\n",
       "      <td>410277</td>\n",
       "      <td>667450</td>\n",
       "      <td>1.25104e+06</td>\n",
       "      <td>489690</td>\n",
       "      <td>526270</td>\n",
       "      <td>409749</td>\n",
       "      <td>501370</td>\n",
       "      <td>367017</td>\n",
       "      <td>422633</td>\n",
       "      <td>662919</td>\n",
       "      <td>499906</td>\n",
       "      <td>372982</td>\n",
       "      <td>463719</td>\n",
       "      <td>441446</td>\n",
       "      <td>605540</td>\n",
       "      <td>1.01165e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>580408</td>\n",
       "      <td>422509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128401</td>\n",
       "      <td>165094</td>\n",
       "      <td>164752</td>\n",
       "      <td>196199</td>\n",
       "      <td>202085</td>\n",
       "      <td>290335</td>\n",
       "      <td>478489</td>\n",
       "      <td>323422</td>\n",
       "      <td>257822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>777640</td>\n",
       "      <td>304265</td>\n",
       "      <td>519121</td>\n",
       "      <td>337760</td>\n",
       "      <td>467145</td>\n",
       "      <td>435704</td>\n",
       "      <td>825249</td>\n",
       "      <td>371357</td>\n",
       "      <td>465614</td>\n",
       "      <td>389901</td>\n",
       "      <td>402174</td>\n",
       "      <td>580773</td>\n",
       "      <td>748877</td>\n",
       "      <td>548652</td>\n",
       "      <td>455076</td>\n",
       "      <td>363699</td>\n",
       "      <td>406712</td>\n",
       "      <td>409794</td>\n",
       "      <td>675653</td>\n",
       "      <td>1.31317e+06</td>\n",
       "      <td>486805</td>\n",
       "      <td>524048</td>\n",
       "      <td>414526</td>\n",
       "      <td>500782</td>\n",
       "      <td>376713</td>\n",
       "      <td>422506</td>\n",
       "      <td>658932</td>\n",
       "      <td>499775</td>\n",
       "      <td>373644</td>\n",
       "      <td>473163</td>\n",
       "      <td>437879</td>\n",
       "      <td>610145</td>\n",
       "      <td>1.01658e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>586789</td>\n",
       "      <td>424826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128142</td>\n",
       "      <td>166291</td>\n",
       "      <td>164949</td>\n",
       "      <td>194214</td>\n",
       "      <td>200196</td>\n",
       "      <td>290309</td>\n",
       "      <td>479628</td>\n",
       "      <td>319827</td>\n",
       "      <td>257101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>248232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>844989</td>\n",
       "      <td>304099</td>\n",
       "      <td>527747</td>\n",
       "      <td>339215</td>\n",
       "      <td>461398</td>\n",
       "      <td>434625</td>\n",
       "      <td>870107</td>\n",
       "      <td>370872</td>\n",
       "      <td>478565</td>\n",
       "      <td>395082</td>\n",
       "      <td>404658</td>\n",
       "      <td>586842</td>\n",
       "      <td>742876</td>\n",
       "      <td>550296</td>\n",
       "      <td>456568</td>\n",
       "      <td>364658</td>\n",
       "      <td>412593</td>\n",
       "      <td>411748</td>\n",
       "      <td>670075</td>\n",
       "      <td>1.3444e+06</td>\n",
       "      <td>488389</td>\n",
       "      <td>521753</td>\n",
       "      <td>414411</td>\n",
       "      <td>509365</td>\n",
       "      <td>379837</td>\n",
       "      <td>426848</td>\n",
       "      <td>658654</td>\n",
       "      <td>504904</td>\n",
       "      <td>376708</td>\n",
       "      <td>482143</td>\n",
       "      <td>438596</td>\n",
       "      <td>614426</td>\n",
       "      <td>1.01398e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>591783</td>\n",
       "      <td>427481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129047</td>\n",
       "      <td>168161</td>\n",
       "      <td>165685</td>\n",
       "      <td>198284</td>\n",
       "      <td>201369</td>\n",
       "      <td>291356</td>\n",
       "      <td>488185</td>\n",
       "      <td>326701</td>\n",
       "      <td>262444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>867841</td>\n",
       "      <td>283139</td>\n",
       "      <td>526553</td>\n",
       "      <td>346840</td>\n",
       "      <td>494455</td>\n",
       "      <td>443482</td>\n",
       "      <td>870627</td>\n",
       "      <td>386738</td>\n",
       "      <td>502107</td>\n",
       "      <td>400695</td>\n",
       "      <td>389920</td>\n",
       "      <td>551629</td>\n",
       "      <td>719836</td>\n",
       "      <td>547124</td>\n",
       "      <td>465958</td>\n",
       "      <td>378747</td>\n",
       "      <td>405066</td>\n",
       "      <td>396030</td>\n",
       "      <td>706263</td>\n",
       "      <td>1.34895e+06</td>\n",
       "      <td>477450</td>\n",
       "      <td>513397</td>\n",
       "      <td>400987</td>\n",
       "      <td>529857</td>\n",
       "      <td>356915</td>\n",
       "      <td>435763</td>\n",
       "      <td>683248</td>\n",
       "      <td>508543</td>\n",
       "      <td>376808</td>\n",
       "      <td>480984</td>\n",
       "      <td>440354</td>\n",
       "      <td>607227</td>\n",
       "      <td>1.03449e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>584234</td>\n",
       "      <td>431880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125938</td>\n",
       "      <td>167809</td>\n",
       "      <td>165561</td>\n",
       "      <td>200513</td>\n",
       "      <td>202093</td>\n",
       "      <td>295640</td>\n",
       "      <td>480425</td>\n",
       "      <td>327413</td>\n",
       "      <td>255891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0 City of London Barking & Dagenham  Barnet  Bexley   Brent Bromley  Camden Croydon  Ealing Enfield Greenwich Hackney Hammersmith & Fulham Haringey  Harrow Havering Hillingdon Hounslow Islington Kensington & Chelsea Kingston upon Thames Lambeth Lewisham  Merton  Newham Redbridge Richmond upon Thames Southwark  Sutton Tower Hamlets Waltham Forest Wandsworth  Westminster  Unnamed: 34 Inner London Outer London  Unnamed: 37 NORTH EAST NORTH WEST YORKS & THE HUMBER EAST MIDLANDS WEST MIDLANDS EAST OF ENGLAND  LONDON SOUTH EAST SOUTH WEST  Unnamed: 47 England\n",
       "295 2019-07-01         756407             297426  514668  338346  473849  434257  890288  365875  475592  388053    397828  555779               725253   550393  446095   367679     398547   397246    629281          1.27544e+06               502895  510045   410983  504702  359106    414968               657619    499663  373534        431290         418743     585174       948507          NaN       569219       421920          NaN     129756     166137             165119        193549        197938          291700  478858     322863     258449          NaN  248652\n",
       "296 2019-08-01         813770             299421  528577  337523  488784  442189  863171  364540  474627  393033    396858  567269               729659   544194  450373   367502     397385   401911    643335          1.24853e+06               508405  519956   416885  517489  361920    421319               657974    496718  368908        441364         427416     592251       905951          NaN       571439       425263          NaN     131515     167490             165441        195268        200858          290623  472872     323122     258241          NaN  249294\n",
       "297 2019-09-01         810455             304778  526670  333340  501533  441058  838170  365226  473162  386806    403730  573270               735538   553640  453155   366447     403945   406930    655061          1.23018e+06               504867  520403   420341  515391  368687    414268               648147    507466  372899        447629         432270     605559       922687          NaN       577554       425804          NaN     131952     166796             165407        194808        200969          291944  477779     324357     258751          NaN  249771\n",
       "298 2019-10-01         826227             304579  525678  332920  494770  439178  804713  364413  477369  392721    401559  566979               719932   554123  453783   367102     403300   413132    645212          1.19044e+06               488211  515947   421258  509006  369972    411874               643769    513615  369917        452040         434921     600642       927735          NaN       574464       424942          NaN     129462     166640             166494        194674        200116          291196  474156     323278     258880          NaN  249152\n",
       "299 2019-11-01         776894             306390  522639  333657  432188  436080  825336  367585  475492  393255    405337  559758               719751   559426  450109   365861     407706   410071    630659          1.19405e+06               490420  519410   415893  501570  363114    413882               650949    510619  374775        450989         435568     601650       955265          NaN       573932       423311          NaN     129658     165808             164499        194855        200896          288781  468983     322512     256875          NaN  247951\n",
       "300 2019-12-01         737275             301283  519306  336302  427126  438682  807124  369568  469662  400182    398024  552785               728698   565582  446900   365886     404843   409569    648969          1.23176e+06               487696  521705   413462  500651  360934    424631               655378    505499  372581        456436         437333     605560       960943          NaN       575132       423156          NaN     129504     164893             165818        194553        198644          290814  478576     321972     256577          NaN  248250\n",
       "301 2020-01-01         747611             303653  518542  334765  423161  435532  815512  371227  466491  390589    396833  558321               740048   563151  447269   362423     406622   410277    667450          1.25104e+06               489690  526270   409749  501370  367017    422633               662919    499906  372982        463719         441446     605540  1.01165e+06          NaN       580408       422509          NaN     128401     165094             164752        196199        202085          290335  478489     323422     257822          NaN  248950\n",
       "302 2020-02-01         777640             304265  519121  337760  467145  435704  825249  371357  465614  389901    402174  580773               748877   548652  455076   363699     406712   409794    675653          1.31317e+06               486805  524048   414526  500782  376713    422506               658932    499775  373644        473163         437879     610145  1.01658e+06          NaN       586789       424826          NaN     128142     166291             164949        194214        200196          290309  479628     319827     257101          NaN  248232\n",
       "303 2020-03-01         844989             304099  527747  339215  461398  434625  870107  370872  478565  395082    404658  586842               742876   550296  456568   364658     412593   411748    670075           1.3444e+06               488389  521753   414411  509365  379837    426848               658654    504904  376708        482143         438596     614426  1.01398e+06          NaN       591783       427481          NaN     129047     168161             165685        198284        201369          291356  488185     326701     262444          NaN  251539\n",
       "304 2020-04-01         867841             283139  526553  346840  494455  443482  870627  386738  502107  400695    389920  551629               719836   547124  465958   378747     405066   396030    706263          1.34895e+06               477450  513397   400987  529857  356915    435763               683248    508543  376808        480984         440354     607227  1.03449e+06          NaN       584234       431880          NaN     125938     167809             165561        200513        202093          295640  480425     327413     255891          NaN  250874"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "properties.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tE9Sqt9-oAta"
   },
   "source": [
    "**2.2. Cleaning the data**\n",
    "\n",
    "You might find you need to transpose your dataframe, check out what its row indexes are, and reset the index. \n",
    "\n",
    "You  also might find you need to assign the values of the first row to your column headings  . (Hint: recall the .columns feature of DataFrames, as well as the iloc[] method).\n",
    "\n",
    "Don't be afraid to use StackOverflow for help  with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdAu1A3YoH_r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1uLbJAsoIjK"
   },
   "source": [
    "**2.3. Cleaning the data (part 2)**\n",
    "\n",
    "You might we have to **rename** a couple columns. How do you do this? The clue's pretty bold..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKkmn1AnoVZS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jy8BzXHmoWEw"
   },
   "source": [
    "**2.4.Transforming the data**\n",
    "\n",
    "Remember what Wes McKinney said about tidy data? \n",
    "\n",
    "You might need to **melt** your DataFrame here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2wM0qLuo2Zt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7kIsgAo7o3mf"
   },
   "source": [
    "Remember to make sure your column data types are all correct. Average prices, for example, should be floating point numbers... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcR4IHbcpOaq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knLUXHLypOtw"
   },
   "source": [
    "**2.5. Cleaning the data (part 3)**\n",
    "\n",
    "Do we have an equal number of observations in the ID, Average Price, Month, and London Borough columns? Remember that there are only 32 London Boroughs. How many entries do you have in that column? \n",
    "\n",
    "Check out the contents of the London Borough column, and if you find null values, get rid of them however you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BnvTW5a3p0fC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PGEx6mJsp6dG"
   },
   "source": [
    "**2.6. Visualizing the data**\n",
    "\n",
    "To visualize the data, why not subset on a particular London Borough? Maybe do a line plot of Month against Average Price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAg5pT9cqHAR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aWTPqSJeqHnC"
   },
   "source": [
    "To limit the number of data points you have, you might want to extract the year from every month value your *Month* column. \n",
    "\n",
    "To this end, you *could* apply a ***lambda function***. Your logic could work as follows:\n",
    "1. look through the `Month` column\n",
    "2. extract the year from each individual value in that column \n",
    "3. store that corresponding year as separate column. \n",
    "\n",
    "Whether you go ahead with this is up to you. Just so long as you answer our initial brief: which boroughs of London have seen the greatest house price increase, on average, over the past two decades? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e0DF92cyqnu8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2knuTxAEqoJ4"
   },
   "source": [
    "**3. Modeling**\n",
    "\n",
    "Consider creating a function that will calculate a ratio of house prices, comparing the price of a house in 2018 to the price in 1998.\n",
    "\n",
    "Consider calling this function create_price_ratio.\n",
    "\n",
    "You'd want this function to:\n",
    "1. Take a filter of dfg, specifically where this filter constrains the London_Borough, as an argument. For example, one admissible argument should be: dfg[dfg['London_Borough']=='Camden'].\n",
    "2. Get the Average Price for that Borough, for the years 1998 and 2018.\n",
    "4. Calculate the ratio of the Average Price for 1998 divided by the Average Price for 2018.\n",
    "5. Return that ratio.\n",
    "\n",
    "Once you've written this function, you ultimately want to use it to iterate through all the unique London_Boroughs and work out the ratio capturing the difference of house prices between 1998 and 2018.\n",
    "\n",
    "Bear in mind: you don't have to write a function like this if you don't want to. If you can solve the brief otherwise, then great! \n",
    "\n",
    "***Hint***: This section should test the skills you acquired in:\n",
    "- Python Data Science Toolbox - Part One, all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKTyr437UgDa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzYUI7FxJpgv"
   },
   "source": [
    "### 4. Conclusion\n",
    "What can you conclude? Type out your conclusion below. \n",
    "\n",
    "Look back at your notebook. Think about how you might summarize what you have done, and prepare a quick presentation on it to your mentor at your next meeting. \n",
    "\n",
    "We hope you enjoyed this practical project. It should have consolidated your data hygiene and pandas skills by looking at a real-world problem involving just the kind of dataset you might encounter as a budding data scientist. Congratulations, and looking forward to seeing you at the next step in the course! "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Springboard Data Science Career Track Unit 4 Challenge - Tier 3 Complete .ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
